A União Europeia divulgou as diretrizes éticas que deverão nortear o desenvolvimento de tecnologias de inteligência artificial a serem adotadas no bloco econômico.O documento cobre aplicações nas mais diversas atividades, da seleção as publicações mostradas nas redes sociais a sistemas de avaliação de crédito.A organização define a inteligência artificial (IA) como "sistemas que mostram comportamento inteligente: analisando seu ambiente, eles podem executar várias tarefas com algum grau de autonomia para atingir metas específicas."O documento faz parte de um processo da União Europeia para estabelecer uma visão "centrada em humanos" para a construção de soluções "confiáveis" desse tipo de sistemas. Esta pode se materializar tanto em legislações e normas administrativas como em orientações gerais para os fabricantes e projetos de pesquisa.Benefício aos seres humanos sem discriminaçãoUma das diretrizes é a relevância da participação e do controle dos seres humanos, com objetos técnicos que promovam o papel e os direitos das pessoas, e não prejudiquem estas mesmas pessoas.Uma orientação complementar é a garantia de que os sistemas considerem a diversidade de segmentos e representações humanas (incluindo gênero, raça e etnia, orientação sexual e classe, entre outros), evitando atuações que gerem discriminação.Segundo o documento, os sistemas de IA devem ser "robustos" e "seguros", de modo a evitar erros ou a terem condição de lidar com estes, corrigindo eventuais inconsistências. Esses problemas podem ter sérios impactos na sociedade, como a discriminação de pessoas no acesso a um serviço ou até mesmo quedas de bolsas de valores, cujas compras e vendas de ações utilizam essas tecnologias.Pelo documento, essas soluções técnicas devem assegurar a privacidade e o controle dos cidadãos sobre seus dados. As informações coletadas sobre um indivíduo não podem ser utilizadas para prejudicá-lo, como em decisões automatizadas que o discriminam em relação a alguém. Estudos já mostraram como essas tecnologias podem incorporar vieses, privilegiando, por exemplo, pessoas brancas em detrimento de negros na caracterização ou na oferta de um serviço.Ética da inteligência artificialSão sete elementos essenciais para assegurar uma inteligência artificial confiável para os seres humanos.Iniciativa e controle por humanos: os sistemas de IA devem levar a sociedades equitativas, apoiando a iniciativa humana e os direitos fundamentais, sem diminuir, limitar nem orientar indevidamente a autonomia humana.Robustez e segurança: uma IA que assegure confiança exige que os algoritmos sejam suficientemente seguros, fiáveis e robustos para resolver os erros ou incoerências durante todas as fases do ciclo de vida dos sistemas de IA.Privacidade e governança dos dados: os cidadãos devem ter pleno controle sobre os seus próprios dados, que não deverão ser utilizados para os prejudicar ou discriminar.Transparência: a rastreabilidade dos sistemas de IA deve ser assegurada.Diversidade, não discriminação e equidade: os sistemas de IA devem ter em conta todas as capacidades, competências e exigências das pessoas e garantir a acessibilidade.Bem-estar societal e ambiental: os sistemas de IA devem ser utilizados para encorajar uma evolução social positiva e reforçar a sustentabilidade e a responsabilidade ecológica.Responsabilização: devem ser criados mecanismos para assegurar a responsabilidade e a responsabilização em relação aos sistemas de IA e às suas consequências."A dimensão ética da Inteligência Artificial não é só um luxo ou um acréscimo. É somente com confiança que nossa sociedade pode se beneficiar plenamente dessas tecnologias. Uma IA ética é uma proposta que traz ganhos e que pode ser uma vantagem competitiva para a Europa: ser uma líder de tecnologias de IA centradas em pessoas que usuários possam confiar," disse o vice-presidente para o Mercado Único Digital da União Europeia, Andrus Ansip.